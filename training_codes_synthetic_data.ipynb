{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Ss2gL4OwrnPe",
        "outputId": "76bc30e3-cd96-47d3-b6a5-ac100b7e4234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0 , Pre-training ======================\n",
            "epoch: 0 \t loss: 1.555291771888733\n",
            "epoch: 20 \t loss: 0.6894027590751648\n",
            "epoch: 40 \t loss: 0.3929479122161865\n",
            "epoch: 60 \t loss: 0.2863925099372864\n",
            "epoch: 80 \t loss: 0.2142537236213684\n",
            "epoch: 100 \t loss: 0.16822315752506256\n",
            "epoch: 120 \t loss: 0.1522437483072281\n",
            "epoch: 140 \t loss: 0.12958483397960663\n",
            "epoch: 160 \t loss: 0.10898815095424652\n",
            "epoch: 180 \t loss: 0.10477417707443237\n",
            "epoch: 200 \t loss: 0.0828423872590065\n",
            "epoch: 220 \t loss: 0.09115253388881683\n",
            "epoch: 240 \t loss: 0.07166553288698196\n",
            "epoch: 260 \t loss: 0.06990953534841537\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2023303071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializeThs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY0_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU0_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV0_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-2023303071.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Y0_t, r, U0_t, V0_t, num_l)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m## Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mS_t\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY0_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mths_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd_lowrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY0_t\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mS_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mSigsqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mU_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigsqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lowrank.py\u001b[0m in \u001b[0;36msvd_lowrank\u001b[0;34m(A, q, niter, M)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0msvd_lowrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             )\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_svd_lowrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lowrank.py\u001b[0m in \u001b[0;36m_svd_lowrank\u001b[0;34m(A, q, niter, M)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_approximate_basis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lowrank.py\u001b[0m in \u001b[0;36mget_approximate_basis\u001b[0;34m(A, q, niter, M)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import scipy.sparse.linalg as lina\n",
        "import time\n",
        "\n",
        "## ================Preparations====================\n",
        "device = torch.device('cuda:0')\n",
        "datatype = torch.float32\n",
        "\n",
        "## ================Parameters======================\n",
        "r \t\t\t\t= 5\t\t\t# underlying rank\n",
        "d1 \t\t\t\t= 1000\t\t# size (num. of rows)\n",
        "d2 \t\t\t\t= 1000\t\t# size (num. of columns)\n",
        "alpha \t\t\t= 0.1\t\t# fraction of outliers\n",
        "step_initial \t= 0.5\t\t# initial value of step size (eta in the paper)\n",
        "ths_initial \t= 1e-3\t\t# initial value of thresholds (zeta in the paper)\n",
        "maxIt \t\t\t= 15\t\t# num. of layers you want to train\n",
        "\n",
        "## =============Generate RPCA problems=============\n",
        "def generate_problem(r,d1,d2,alpha):\n",
        "    U0_t \t\t= torch.randn(d1,r,dtype = datatype, device = device)/math.sqrt(d1)\n",
        "    V0_t \t\t= torch.randn(d1,r,dtype = datatype, device = device)/math.sqrt(d2)\n",
        "    idx \t\t= torch.randperm(d1*d2, device = device)\n",
        "    idx \t\t= idx[:math.floor(alpha * d1*d2)]\n",
        "    Y0_t \t\t= torch.mm(U0_t,V0_t.t())\n",
        "    Y0_t \t\t= Y0_t.reshape(-1)\n",
        "    s_range\t\t= torch.mean(torch.abs(Y0_t))\n",
        "    S0_t \t\t= torch.rand(len(idx), dtype = datatype, device = device)\n",
        "    S0_t \t\t= s_range * (2.0 * S0_t - 1.0)\n",
        "    Y0_t[idx] \t= Y0_t[idx] + S0_t\n",
        "    Y0_t \t\t= Y0_t.reshape((d1,d2))\n",
        "    return U0_t, V0_t, Y0_t\n",
        "\n",
        "## ===================LRPCA model===================\n",
        "class MatNet(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(type(self),self).__init__()\n",
        "\t\tself.ths_v \t\t= [nn.Parameter(Variable(torch.tensor(ths_initial, dtype=datatype, device = device), requires_grad=True)) for t in range(maxIt)]\n",
        "\t\tself.step \t\t= [nn.Parameter(Variable(torch.tensor(step_initial, dtype=datatype, device = device), requires_grad=True)) for t in range(maxIt)]\n",
        "\t\tself.ths_backup\t= [torch.tensor(0.0, dtype=datatype, device = device) for t in range(maxIt)]\n",
        "\n",
        "\tdef thre(self, inputs, threshold):\n",
        "\t\tout = torch.sign(inputs) * torch.max( torch.abs(inputs) - threshold, torch.zeros([1, 1], dtype=datatype, device=device) )\n",
        "\t\treturn out\n",
        "\n",
        "\tdef forward(self, Y0_t, r, U0_t, V0_t, num_l):\n",
        "\n",
        "\t\t## Initialization\n",
        "\t\tS_t =  self.thre(Y0_t, self.ths_v[0])\n",
        "\t\tL, Sigma, R = torch.svd_lowrank(Y0_t-S_t, q = r, niter = 4)\n",
        "\t\tSigsqrt = torch.diag(torch.sqrt(Sigma))\n",
        "\t\tU_t = torch.mm(L, Sigsqrt)\n",
        "\t\tV_t = torch.mm(R, Sigsqrt)\n",
        "\n",
        "        ## Main Loop in LRPCA\n",
        "\t\tfor t in range(1, num_l):\n",
        "\t\t\tYmUV = Y0_t - torch.mm(U_t, V_t.t())\n",
        "\t\t\tS_t =  self.thre(YmUV, self.ths_v[t])\n",
        "\t\t\tE_t = YmUV - S_t\n",
        "\t\t\tVkernel = torch.inverse(V_t.t() @ V_t)\n",
        "\t\t\tUkernel = torch.inverse(U_t.t() @ U_t)\n",
        "\t\t\tUnew = U_t + self.step[t] * (torch.mm(E_t,V_t) @ Vkernel)\n",
        "\t\t\tVnew = V_t + self.step[t] * (torch.mm(U_t.t(),E_t).t() @ Ukernel)\n",
        "\t\t\tU_t = Unew\n",
        "\t\t\tV_t = Vnew\n",
        "\n",
        "\t\t## loss function in training\n",
        "\t\tloss = (torch.mm(U_t, V_t.t()) - torch.mm(U0_t, V0_t.t())).norm()\n",
        "\t\treturn loss\n",
        "\n",
        "\tdef InitializeThs(self, en_l):\n",
        "\t\tself.ths_v[en_l].data = torch.clone(self.ths_v[en_l-1].data * 0.1)\n",
        "\n",
        "\tdef CheckNegative(self):\n",
        "\t\tisNegative = False;\n",
        "\t\tfor t in range(maxIt):\n",
        "\t\t\tif(self.ths_v[t].data < 0):\n",
        "\t\t\t\tisNegative = True;\n",
        "\t\tif(isNegative):\n",
        "\t\t\tfor t in range(maxIt):\n",
        "\t\t\t\tself.ths_v[t].data = torch.clone(self.ths_backup[t])\n",
        "\t\telse:\n",
        "\t\t\tfor t in range(maxIt):\n",
        "\t\t\t\tself.ths_backup[t] = torch.clone(self.ths_v[t].data)\n",
        "\t\treturn isNegative;\n",
        "\n",
        "\tdef EnableSingleLayer(self,en_l):\n",
        "\t\tfor t in range(maxIt):\n",
        "\t\t\tself.ths_v[t].requires_grad = False\n",
        "\t\t\tself.step[t].requires_grad = False\n",
        "\t\tself.ths_v[en_l].requires_grad = True\n",
        "\t\tself.step[en_l].requires_grad = True\n",
        "\n",
        "\tdef EnableLayers(self, num_l):\n",
        "\t\tfor t in range(num_l):\n",
        "\t\t\tself.ths_v[t].requires_grad = True\n",
        "\t\t\tself.step[t].requires_grad = True\n",
        "\t\tfor t in range(num_l,maxIt):\n",
        "\t\t\tself.ths_v[t].requires_grad = False\n",
        "\t\t\tself.step[t].requires_grad = False\n",
        "\n",
        "\n",
        "## =================Training Scripts======================\n",
        "Nepoches_pre \t= 500\n",
        "Nepoches_full \t= 1000\n",
        "lr_fac \t\t\t= 1.0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# basic learning rate\n",
        "\n",
        "net = MatNet()\n",
        "optimizers = []\n",
        "for i in range(maxIt):\n",
        "    optimizer = optim.SGD({net.ths_v[i]},lr = lr_fac * ths_initial / 5000.0)\t# optimizer for each layer\n",
        "    optimizer.add_param_group({'params': [net.step[i]], 'lr': lr_fac * 0.1})\t# learning rate for each layer\n",
        "    optimizers.append(optimizer)\n",
        "\n",
        "## =================Layerwise Training======================\n",
        "start = time.time()\n",
        "for stage in range(maxIt):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# in k-th stage, we train the k-th layer\n",
        "\n",
        "\t## Pre-training: only train the k-th layer\n",
        "\tprint('Layer ',stage,', Pre-training ======================')\n",
        "\tif(stage > 6):\n",
        "\t\tNepoches_full = 500\n",
        "\tif(stage > 0):\n",
        "\t\toptimizers[stage].param_groups[0]['lr'] = net.ths_v[stage-1].data * lr_fac / 5000.0\n",
        "\tfor epoch in range(Nepoches_pre):\n",
        "\t\tfor i in range(maxIt):\n",
        "\t\t\toptimizers[i].zero_grad()\n",
        "\n",
        "\t\tU0_t,V0_t,Y0_t = generate_problem(r,d1,d2,alpha)\n",
        "\t\tnet.EnableSingleLayer(stage)\n",
        "\t\tif(stage > 0):\n",
        "\t\t\tnet.InitializeThs(stage)\n",
        "\t\tloss = net(Y0_t, r, U0_t, V0_t, stage+1)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizers[stage].step()\n",
        "\n",
        "\t\tif(epoch % 10 == 0):\n",
        "\t\t\tif net.CheckNegative():\n",
        "\t\t\t\tprint(\"Negative detected, restored\")\n",
        "\n",
        "\t\tlr = optimizers[stage].param_groups[0]['lr']\n",
        "\t\tif epoch % 20 == 0:\n",
        "\t\t\tprint(\"epoch: \" + str(epoch), \"\\t loss: \" + str(loss.item()))\n",
        "\n",
        "\t# Full-training: train 0~k th layers\n",
        "\tprint('Layer ',stage,', Full-training =====================')\n",
        "\tif stage == 0:\n",
        "\t\tcontinue\n",
        "\n",
        "\tfor epoch in range(Nepoches_full):\n",
        "\t\tfor i in range(maxIt):\n",
        "\t\t\toptimizers[i].zero_grad()\n",
        "\n",
        "\t\tU0_t,V0_t,Y0_t = generate_problem(r,d1,d2,alpha)\n",
        "\t\tnet.EnableLayers(stage+1)\n",
        "\t\tloss = net(Y0_t, r, U0_t, V0_t, stage+1)\n",
        "\t\tloss.backward()\n",
        "\n",
        "\t\tfor i in range(stage+1):\n",
        "\t\t\toptimizers[i].step()\n",
        "\n",
        "\t\tif epoch % 20 == 0:\n",
        "\t\t\tprint(\"epoch: \" + str(epoch), \"\\t loss: \" + str(loss.item()))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Training end. Time: \" + str(end - start))\n",
        "\n",
        "## =====================Save model to .mat file ========================\n",
        "result_ths \t= np.zeros((maxIt,))\n",
        "result_stp1 = np.zeros((maxIt,))\n",
        "result_stp2 = np.zeros((maxIt,))\n",
        "for i in range(maxIt):\n",
        "\tresult_ths[i] \t= net.ths_v[i].data.cpu().numpy()\n",
        "\tresult_stp1[i] \t= net.step[i].data.cpu().numpy()\n",
        "\n",
        "spath = 'LRPCA_alpha'+str(alpha)+'.mat'\n",
        "sio.savemat(spath, {'ths':result_ths, 'step':result_stp1})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}